<!doctype html>
<html>
<head>
<meta charset="utf-8"/>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>阮一峰：贝叶斯推断及其互联网应用 - 邮件服务 - Linux.CN</title>
<link rel="stylesheet" href="../css/article.css" />
</head>
<body>
<div class="m-content">
<h1>阮一峰：贝叶斯推断及其互联网应用 - 邮件服务 - Linux.CN</h1>
<div id="main-content"><p><img src="http://img.linux.net.cn/data/attachment/album/201302/25/101358v4euuhulkd90ee4f.jpg" alt="" /></p><p><strong>一、什么是贝叶斯推断</strong></p><p>贝叶斯推断（<a rel="external nofollow" target="_blank" href="http://en.wikipedia.org/wiki/Bayesian_inference">Bayesian inference</a>）是一种统计学方法，用来估计统计量的某种性质。</p><p>它是贝叶斯定理（<a rel="external nofollow" target="_blank" href="http://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes' theorem</a>）的应用。英国数学家托马斯·贝叶斯（Thomas Bayes）在1763年发表的一篇论文中，首先提出了这个定理。</p><p><img src="http://img.linux.net.cn/data/attachment/album/201302/25/101359evptapzaxnmqxvr7.jpg" alt="" /></p><p>贝叶斯推断与其他统计学推断方法截然不同。它建立在主观判断的基础上，也就是说，你可以不需要客观证据，先估计一个值，然后根据推断结果不断修正。正是因为它的主观性太强，曾经遭到许多统计学家的诟病。</p><p>贝叶斯推断需要大量的计算，因此历史上很长一段时间，无法得到广泛应用。只有计算机诞生以后，它才获得真正的重视。人们发现，许多统计量是无法事先进行客观判断的，而互联网时代出现的大型数据集，再加上高速运算能力，为验证这些统计量提供了方便，也为应用贝叶斯推断创造了条件，它的威力正在日益显现。</p><p><strong>二、贝叶斯定理</strong></p><p>要理解贝叶斯推断，必须先理解贝叶斯定理。后者实际上就是计算"条件概率"的公式。</p><p>所谓"条件概率"（Conditional probability），就是指在事件B发生的情况下，事件A发生的概率，用P(A|B)来表示。</p><p><img src="http://img.linux.net.cn/data/attachment/album/201302/25/101400nfn27pg70n2272gv.jpg" alt="" /></p><p>根据文氏图，可以很清楚地看到在事件B发生的情况下，事件A发生的概率就是P(A∩B)除以P(B)。</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(A%7CB)%3D%5Cfrac%7BP(A%5Ccap%20B)%7D%7BP(B)%7D&amp;chs=70" alt="" /></p><p>因此，</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(A%5Ccap%20B)%3DP(A%7CB)%7BP(B)%7D&amp;chs=40" alt="" /></p><p>同理可得，</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(A%5Ccap%20B)%3DP(B%7CA)%7BP(A)%7D&amp;chs=40" alt="" /></p><p>所以，</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(A%7CB)%7BP(B)%7D%3DP(B%7CA)%7BP(A)%7D&amp;chs=40" alt="" /></p><p>即</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(A%7CB)%3D%5Cfrac%7BP(B%7CA)%7BP(A)%7D%7D%7B%7BP(B)%7D%7D&amp;chs=70" alt="" /></p><p>这就是条件概率的计算公式。</p><p><strong>三、全概率公式</strong></p><p>由于后面要用到，所以除了条件概率以外，这里还要推导全概率公式。</p><p>假定样本空间S，是两个事件A与A'的和。</p><p><img src="http://img.linux.net.cn/data/attachment/album/201302/25/101402i1ama8c11gfgi6tf.jpg" alt="" /></p><p>上图中，红色部分是事件A，绿色部分是事件A'，它们共同构成了样本空间S。</p><p>在这种情况下，事件B可以划分成两个部分。</p><p><img src="http://img.linux.net.cn/data/attachment/album/201302/25/101404fwdwrwx6rw722rxx.jpg" alt="" /></p><p>即</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(B)%3DP(B%5Ccap%20A)%2BP(B%5Ccap%20A')&amp;chs=40" alt="" /></p><p>在上一节的推导当中，我们已知</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(B%5Ccap%20A)%3DP(B%7CA)P(A)&amp;chs=40" alt="" /></p><p>所以，</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(B)%3DP(B%7CA)P(A)%2BP(B%7CA')P(A')&amp;chs=40" alt="" /></p><p>这就是全概率公式。它的含义是，如果A和A'构成样本空间的一个划分，那么事件B的概率，就等于A和A'的概率分别乘以B的条件概率之和。</p><p>将这个公式代入上一节的条件概率公式，就得到了条件概率的另一种写法：</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(A%7CB)%3D%5Cfrac%7BP(B%7CA)P(A)%7D%7BP(B%7CA)P(A)%2BP(B%7CA')P(A')%7D&amp;chs=70" alt="" /></p><p><strong>四、贝叶斯推断的含义</strong></p><p>对条件概率公式进行变形，可以得到如下形式：</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(A%7CB)%3DP(A)%5Cfrac%7BP(B%7CA)%7D%7BP(B)%7D&amp;chs=70" alt="" /></p><p>我们把P(A)称为"先验概率"（Prior probability），即在B事件发生之前，我们对A事件概率的一个判断。P(A|B)称为"后验概率"（Posterior probability），即在B事件发生之后，我们对A事件概率的重新评估。P(B|A)/P(B)称为"可能性函数"（Likelyhood），这是一个调整因子，使得预估概率更接近真实概率。</p><p>所以，条件概率可以理解成下面的式子：</p><blockquote>
<p>　　后验概率　＝　先验概率 ｘ 调整因子</p>
</blockquote><p><strong>这就是贝叶斯推断的含义。我们先预估一个"先验概率"，然后加入实验结果，看这个实验到底是增强还是削弱了"先验概率"，由此得到更接近事实的"后验概率"。</strong></p><p>在这里，如果"可能性函数"P(B|A)/P(B)&gt;1，意味着"先验概率"被增强，事件A的发生的可能性变大；如果"可能性函数"=1，意味着B事件无助于判断事件A的可能性；如果"可能性函数"&lt;1，意味着"先验概率"被削弱，事件A的可能性变小。</p><p><strong>五、【例子】水果糖问题</strong></p><p>为了加深对贝叶斯推断的理解，我们看两个例子。</p><p><img src="http://img.linux.net.cn/data/attachment/album/201302/25/101405ro9rzg98ossn6rk3.jpg" alt="" /></p><p>第一个例子。两个一模一样的碗，一号碗有30颗水果糖和10颗巧克力糖，二号碗有水果糖和巧克力糖各20颗。现在随机选择一个碗，从中摸出一颗糖，发现是水果糖。请问这颗水果糖来自一号碗的概率有多大？</p><p>我们假定，H1表示一号碗，H2表示二号碗。由于这两个碗是一样的，所以P(H1)=P(H2)，也就是说，在取出水果糖之前，这两个碗被选中的概率相同。因此，P(H1)=0.5，我们把这个概率就叫做"先验概率"，即没有做实验之前，来自一号碗的概率是0.5。</p><p>再假定，E表示水果糖，所以问题就变成了在已知E的情况下，来自一号碗的概率有多大，即求P(H1|E)。我们把这个概率叫做"后验概率"，即在E事件发生之后，对P(H1)的修正。</p><p>根据条件概率公式，得到</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(H_%7B1%7D%7CE)%3DP(H_%7B1%7D)%5Cfrac%7BP(E%7CH_%7B1%7D)%7D%7BP(E)%7D&amp;chs=70" alt="" /></p><p>已知，P(H1)等于0.5，P(E|H1)为一号碗中取出水果糖的概率，等于0.75，那么求出P(E)就可以得到答案。根据全概率公式，</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(E)%3DP(E%7CH_%7B1%7D)P(H_%7B1%7D)%2BP(E%7CH_%7B2%7D)P(H_%7B2%7D)&amp;chs=40" alt="" /></p><p>所以，</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(E)%3D0.75%5Ctimes%200.5%2B0.5%5Ctimes%200.5%3D0.625&amp;chs=40" alt="" /></p><p>将数字代入原方程，得到</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(H1%7CE)%3D0.5%5Ctimes%20%5Cfrac%7B0.75%7D%7B0.625%7D%3D0.6&amp;chs=70" alt="" /></p><p>这表明，来自一号碗的概率是0.6。也就是说，取出水果糖之后，H1事件的可能性得到了增强。</p><p><strong>六、【例子】假阳性问题</strong></p><p>第二个例子是一个医学的常见问题，与现实生活关系紧密。</p><p><img src="http://img.linux.net.cn/data/attachment/album/201302/25/1014089fi9oa4nniyqagn4.jpg" alt="" /></p><p>已知某种疾病的发病率是0.001，即1000人中会有1个人得病。现有一种试剂可以检验患者是否得病，它的准确率是0.99，即在患者确实得病的情况下，它有99%的可能呈现阳性。它的误报率是5%，即在患者没有得病的情况下，它有5%的可能呈现阳性。现有一个病人的检验结果为阳性，请问他确实得病的可能性有多大？</p><p>假定A事件表示得病，那么P(A)为0.001。这就是"先验概率"，即没有做试验之前，我们预计的发病率。再假定B事件表示阳性，那么要计算的就是P(A|B)。这就是"后验概率"，即做了试验以后，对发病率的估计。</p><p>根据条件概率公式，</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(A%7CB)%3DP(A)%20%5Cfrac%7BP(B%7CA)%7D%7BP(B)%7D&amp;chs=70" alt="" /></p><p>用全概率公式改写分母，</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(A%7CB)%3DP(A)%20%5Cfrac%7BP(B%7CA)%7D%7BP(B%7CA)P(A)%2BP(B%7C%5Cbar%7BA%7D)P(%5Cbar%7BA%7D)%7D&amp;chs=70" alt="" /></p><p>将数字代入，</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(A%7CB)%3D0.001%5Ctimes%20%20%5Cfrac%7B0.99%7D%7B0.99%5Ctimes%200.001%2B0.05%5Ctimes%200.999%7D%5Capprox%200.019&amp;chs=70" alt="" /></p><p>我们得到了一个惊人的结果，P(A|B)约等于0.019。也就是说，即使检验呈现阳性，病人得病的概率，也只是从0.1%增加到了2%左右。这就是所谓的"假阳性"，即阳性结果完全不足以说明病人得病。</p><p>为什么会这样？为什么这种检验的准确率高达99%，但是可信度却不到2%？答案是与它的误报率太高有关。（【习题】如果误报率从5%降为1%，请问病人得病的概率会变成多少？）</p><p>有兴趣的朋友，还可以算一下"假阴性"问题，即检验结果为阴性，但是病人确实得病的概率有多大。然后问自己，"假阳性"和"假阴性"，哪一个才是医学检验的主要风险？</p><p><img src="http://img.linux.net.cn/data/attachment/album/201302/25/101410e9mm65rqes9mnnq0.jpg" alt="" /></p><p><strong>七、什么是贝叶斯过滤器？</strong></p><p>垃圾邮件是一种令人头痛的顽症，困扰着所有的互联网用户。</p><p>正确识别垃圾邮件的技术难度非常大。传统的垃圾邮件过滤方法，主要有"关键词法"和"校验码法"等。前者的过滤依据是特定的词语；后者则是计算邮件文本的校验码，再与已知的垃圾邮件进行对比。它们的识别效果都不理想，而且很容易规避。</p><p>2002年，<a rel="external nofollow" target="_blank" href="http://www.paulgraham.com/spam.html">Paul Graham</a>提出使用"贝叶斯推断"过滤垃圾邮件。他说，这样做的效果，好得不可思议。1000封垃圾邮件可以过滤掉995封，且没有一个误判。</p><p>另外，这种过滤器还具有自我学习的功能，会根据新收到的邮件，不断调整。收到的垃圾邮件越多，它的准确率就越高。</p><p><strong>八、建立历史资料库</strong></p><p>贝叶斯过滤器是一种统计学过滤器，建立在已有的统计结果之上。所以，我们必须预先提供两组已经识别好的邮件，一组是正常邮件，另一组是垃圾邮件。</p><p>我们用这两组邮件，对过滤器进行"训练"。这两组邮件的规模越大，训练效果就越好。Paul Graham使用的邮件规模，是正常邮件和垃圾邮件各4000封。</p><p>"训练"过程很简单。首先，解析所有邮件，提取每一个词。然后，计算每个词语在正常邮件和垃圾邮件中的出现频率。比如，我们假定"sex"这个词，在4000封垃圾邮件中，有200封包含这个词，那么它的出现频率就是5%；而在4000封正常邮件中，只有2封包含这个词，那么出现频率就是0.05%。（【注释】如果某个词只出现在垃圾邮件中，Paul Graham就假定，它在正常邮件的出现频率是1%，反之亦然。随着邮件数量的增加，计算结果会自动调整。）</p><p>有了这个初步的统计结果，过滤器就可以投入使用了。</p><p><strong>九、贝叶斯过滤器的使用过程</strong></p><p>现在，我们收到了一封新邮件。在未经统计分析之前，我们假定它是垃圾邮件的概率为50%。（【注释】有研究表明，用户收到的电子邮件中，80%是垃圾邮件。但是，这里仍然假定垃圾邮件的"先验概率"为50%。）</p><p>我们用S表示垃圾邮件（spam），H表示正常邮件（healthy）。因此，P(S)和P(H)的先验概率，都是50%。</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(S)%3DP(H)%3D50%25&amp;chs=40" alt="" /></p><p>然后，对这封邮件进行解析，发现其中包含了sex这个词，请问这封邮件属于垃圾邮件的概率有多高？</p><p>我们用W表示"sex"这个词，那么问题就变成了如何计算P(S|W)的值，即在某个词语（W）已经存在的条件下，垃圾邮件（S）的概率有多大。</p><p>根据条件概率公式，马上可以写出</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(S%7CW)%3D%5Cfrac%7BP(W%7CS)P(S)%7D%7BP(W%7CS)P(S)%2BP(W%7CH)P(H)%7D&amp;chs=70" alt="" /></p><p>公式中，P(W|S)和P(W|H)的含义是，这个词语在垃圾邮件和正常邮件中，分别出现的概率。这两个值可以从历史资料库中得到，对sex这个词来说，上文假定它们分别等于5%和0.05%。另外，P(S)和P(H)的值，前面说过都等于50%。所以，马上可以计算P(S|W)的值：</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(S%7CW)%3D%5Cfrac%7B5%25%5Ctimes%2050%25%7D%7B5%25%5Ctimes%2050%25%2B0.05%25%5Ctimes%2050%25%7D%3D99.0%25&amp;chs=70" alt="" /></p><p>因此，这封新邮件是垃圾邮件的概率等于99%。这说明，sex这个词的推断能力很强，将50%的"先验概率"一下子提高到了99%的"后验概率"。</p><p><strong>十、联合概率的计算</strong></p><p>做完上面一步，请问我们能否得出结论，这封新邮件就是垃圾邮件？</p><p>回答是不能。因为一封邮件包含很多词语，一些词语（比如sex）说这是垃圾邮件，另一些说这不是。你怎么知道以哪个词为准？</p><p>Paul Graham的做法是，选出这封信中P(S|W)最高的15个词，计算它们的联合概率。（【注释】如果有的词是第一次出现，无法计算P(S|W)，Paul Graham就假定这个值等于0.4。因为垃圾邮件用的往往都是某些固定的词语，所以如果你从来没见过某个词，它多半是一个正常的词。）</p><p>所谓联合概率，就是指在多个事件发生的情况下，另一个事件发生概率有多大。比如，已知W1和W2是两个不同的词语，它们都出现在某封电子邮件之中，那么这封邮件是垃圾邮件的概率，就是联合概率。</p><p>在已知W1和W2的情况下，无非就是两种结果：垃圾邮件（事件E1）或正常邮件（事件E2）。</p><p><img src="http://img.linux.net.cn/data/attachment/album/201302/25/1014145r1k00u07gd7du77.png" alt="" /></p><p>其中，W1、W2和垃圾邮件的概率分别如下：</p><p><img src="http://img.linux.net.cn/data/attachment/album/201302/25/101416ph5ihvxxaame8nxx.png" alt="" /></p><p>如果假定所有事件都是独立事件（【注释】严格地说，这个假定不成立，但是这里可以忽略），那么就可以计算P(E1)和P(E2)：</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(E_%7B1%7D)%3DP(S%7CW_%7B1%7D)P(S%7CW_%7B2%7D)P(S)&amp;chs=40" alt="" /></p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P(E_%7B2%7D)%3D(1-P(S%7CW_%7B1%7D))(1-P(S%7CW_%7B2%7D))(1-P(S))&amp;chs=40" alt="" /></p><p>又由于在W1和W2已经发生的情况下，垃圾邮件的概率等于下面的式子：</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P%3D%5Cfrac%7BP(E_%7B1%7D)%7D%7BP(E_%7B1%7D)%2BP(E_%7B2%7D)%7D&amp;chs=70" alt="" /></p><p>即</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P%3D%5Cfrac%7BP(S%7CW_%7B1%7D)P(S%7CW_%7B2%7D)P(S)%7D%7BP(S%7CW_%7B1%7D)P(S%7CW_%7B2%7D)P(S)%2B(1-P(S%7CW_%7B1%7D))(1-P(S%7CW_%7B2%7D))(1-P(S))%7D&amp;chs=70" alt="" /></p><p>将P(S)等于0.5代入，得到</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P%3D%5Cfrac%7BP(S%7CW_%7B1%7D)P(S%7CW_%7B2%7D)%7D%7BP(S%7CW_%7B1%7D)P(S%7CW_%7B2%7D)%2B(1-P(S%7CW_%7B1%7D))(1-P(S%7CW_%7B2%7D))%7D&amp;chs=70" alt="" /></p><p>将P(S|W1)记为P1，P(S|W2)记为P2，公式就变成</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P%3D%5Cfrac%7BP_%7B1%7DP_%7B2%7D%7D%7BP_%7B1%7DP_%7B2%7D%2B(1-P_%7B1%7D)(1-P_%7B2%7D)%7D&amp;chs=70" alt="" /></p><p>这就是联合概率的计算公式。如果你不是很理解，点击<a rel="external nofollow" target="_blank" href="http://www.mathpages.com/home/kmath267.htm">这里</a>查看更多的解释。</p><p><strong>十一、最终的计算公式</strong></p><p>将上面的公式扩展到15个词的情况，就得到了最终的概率计算公式：</p><p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=P%3D%5Cfrac%7BP_%7B1%7DP_%7B2%7D%5Ccdot%20%5Ccdot%20%5Ccdot%20P_%7B15%7D%7D%7BP_%7B1%7DP_%7B2%7D%5Ccdot%20%5Ccdot%20%5Ccdot%20P_%7B15%7D%2B(1-P_%7B1%7D)(1-P_%7B2%7D)%5Ccdot%20%5Ccdot%20%5Ccdot%20(1-P_%7B15%7D)%7D&amp;chs=70" alt="" /></p><p>一封邮件是不是垃圾邮件，就用这个式子进行计算。这时我们还需要一个用于比较的门槛值。Paul Graham的门槛值是0.9，概率大于0.9，表示15个词联合认定，这封邮件有90%以上的可能属于垃圾邮件；概率小于0.9，就表示是正常邮件。</p><p>有了这个公式以后，一封正常的信件即使出现sex这个词，也不会被认定为垃圾邮件了。</p><p>使用Google的时候，如果你拼错一个单词，它会提醒你正确的拼法。</p><p>比如，你不小心输入了seperate。</p><p><img src="http://img.linux.net.cn/data/attachment/album/201302/25/101418tyh95jq51yt9jta8.png" alt="" /></p><p>Google告诉你，<a rel="external nofollow" target="_blank" href="http://www.ruanyifeng.com/blog/2004/06/seperate_separate.html">这个词</a>是不存在的，正确的拼法是separate。</p><p><img src="http://img.linux.net.cn/data/attachment/album/201302/25/10141922anmllapsne525v.png" alt="" /></p><p>这就叫做"拼写检查"（spelling corrector）。有好几种方法可以实现这个功能，Google使用的是基于贝叶斯推断的统计学方法。这种方法的特点就是快，很短的时间内处理大量文本，并且有很高的精确度（90%以上）。Google的研发总监<a rel="external nofollow" target="_blank" href="http://en.wikipedia.org/wiki/Peter_Norvig">Peter Norvig</a>，写过一篇著名的<a rel="external nofollow" target="_blank" href="http://norvig.com/spell-correct.html">文章</a>，解释这种方法的原理。</p><p>下面我们就来看看，怎么利用贝叶斯推断，实现"拼写检查"。其实很简单，一小段代码就够了。</p><p><strong>一、原理</strong></p><p>用户输入了一个单词。这时分成两种情况：拼写正确，或者拼写不正确。我们把拼写正确的情况记做c（代表correct），拼写错误的情况记做w（代表wrong）。</p><p>所谓"拼写检查"，就是在发生w的情况下，试图推断出c。从概率论的角度看，就是已知w，然后在若干个备选方案中，找出可能性最大的那个c，也就是求下面这个式子的最大值。</p><blockquote>
<p>　　P(c|w)</p>
</blockquote><p>根据贝叶斯定理：</p><blockquote>
<p>　　P(c|w) = P(w|c) * P(c) / P(w)</p>
</blockquote><p>对于所有备选的c来说，对应的都是同一个w，所以它们的P(w)是相同的，因此我们求的其实是</p><blockquote>
<p>　　P(w|c) * P(c)</p>
</blockquote><p>的最大值。</p><p>P(c)的含义是，某个正确的词的出现"概率"，它可以用"频率"代替。如果我们有一个足够大的文本库，那么这个文本库中每个单词的出现频率，就相当于它的发生概率。某个词的出现频率越高，P(c)就越大。</p><p>P(w|c)的含义是，在试图拼写c的情况下，出现拼写错误w的概率。这需要统计数据的支持，但是为了简化问题，我们假设两个单词在字形上越接近，就有越可能拼错，P(w|C)就越大。举例来说，相差一个字母的拼法，就比相差两个字母的拼法，发生概率更高。你想拼写单词hello，那么错误拼成hallo（相差一个字母）的可能性，就比拼成haallo高（相差两个字母）。</p><p>所以，我们只要找到与输入单词在字形上最相近的那些词，再在其中挑出出现频率最高的一个，就能实现 P(w|c) * P(c) 的最大值。</p><p><strong>二、算法</strong></p><p>最简单的算法，只需要四步就够了。</p><p><strong>第一步，建立一个足够大的文本库。</strong></p><p>网上有一些免费来源，比如<a rel="external nofollow" target="_blank" href="http://www.gutenberg.org/wiki/Main_Page">古登堡计划</a>、<a rel="external nofollow" target="_blank" href="http://en.wiktionary.org/wiki/Wiktionary:Frequency_lists">Wiktionary</a>、<a rel="external nofollow" target="_blank" href="http://www.kilgarriff.co.uk/bnc-readme.html">英国国家语料库</a>等等。</p><p><strong>第二步，取出文本库的每一个单词，统计它们的出现频率。</strong></p><p><strong>第三步，根据用户输入的单词，得到其所有可能的拼写相近的形式。</strong></p><p>所谓"拼写相近"，指的是两个单词之间的"编辑距离"（edit distance）不超过2。也就是说，两个词只相差1到2个字母，只通过----删除、交换、更改和插入----这四种操作中的一种，就可以让一个词变成另一个词。</p><p><strong>第四步，比较所有拼写相近的词在文本库的出现频率。频率最高的那个词，就是正确的拼法。</strong></p><p>根据Peter Norvig的验证，这种算法的精确度大约为60%-70%（10个拼写错误能够检查出6个。）虽然不令人满意，但是能够接受。毕竟它足够简单，计算速度极快。（本文的最后部分，将详细讨论这种算法的缺陷在哪里。）</p><p><strong>三、代码</strong></p><p>我们使用Python语言，实现上一节的算法。</p><p><strong>第一步，把网上下载的文本库保存为<a rel="external nofollow" target="_blank" href="http://norvig.com/big.txt">big.txt</a>文件。</strong>这步不需要编程。</p><p><strong>第二步，加载Python的正则语言模块（re）和collections模块，后面要用到。</strong></p><blockquote>
<p>　　import re, collections</p>
</blockquote><p><strong>第三步，定义words()函数，用来取出文本库的每一个词。</strong></p><blockquote>
<p>　　def words(text): return re.findall('[a-z]+', text.lower())</p>
</blockquote><p>lower()将所有词都转成小写，避免因为大小写不同，而被算作两个词。</p><p><strong>第四步，定义一个train()函数，用来建立一个"字典"结构。</strong>文本库的每一个词，都是这个"字典"的键；它们所对应的值，就是这个词在文本库的出现频率。</p><blockquote>
<p>　　def train(features):</p>
<p>　　　　model = collections.defaultdict(lambda: 1)</p>
<p>　　　　for f in features:</p>
<p>　　　　　　model[f] += 1</p>
<p>　　　　return model</p>
</blockquote><p>collections.defaultdict(lambda: 1)的意思是，每一个词的默认出现频率为1。这是针对那些没有出现在文本库的词。如果一个词没有在文本库出现，我们并不能认定它就是一个不存在的词，因此将每个词出现的默认频率设为1。以后每出现一次，频率就增加1。</p><p><strong>第五步，使用words()和train()函数，生成上一步的"词频字典"，放入变量NWORDS。</strong></p><blockquote>
<p>　　NWORDS = train(words(file('big.txt').read()))</p>
</blockquote><p><strong>第六步，定义edits1()函数，用来生成所有与输入参数word的"编辑距离"为1的词。</strong></p><blockquote>
<p>　　alphabet = 'abcdefghijklmnopqrstuvwxyz'</p>
<p>　　def edits1(word):</p>
<p>　　　　splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]</p>
<p>　　　　deletes = [a + b[1:] for a, b in splits if b]</p>
<p>　　　　transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)&gt;1]</p>
<p>　　　　replaces = [a + c + b[1:] for a, b in splits for c in alphabet if b]</p>
<p>　　　　inserts = [a + c + b for a, b in splits for c in alphabet]</p>
<p>　　　　return set(deletes + transposes + replaces + inserts)</p>
</blockquote><p>edit1()函数中的几个变量的含义如下：</p><blockquote>
<p>　　（1）<strong>splits</strong>：将word依次按照每一位分割成前后两半。比如，'abc'会被分割成 [('', 'abc'), ('a', 'bc'), ('ab', 'c'), ('abc', '')] 。</p>
<p>　　（2）<strong>beletes</strong>：依次删除word的每一位后、所形成的所有新词。比如，'abc'对应的deletes就是 ['bc', 'ac', 'ab'] 。</p>
<p>　　（3）<strong>transposes</strong>：依次交换word的邻近两位，所形成的所有新词。比如，'abc'对应的transposes就是 ['bac', 'acb'] 。</p>
<p>　　（4）<strong>replaces</strong>：将word的每一位依次替换成其他25个字母，所形成的所有新词。比如，'abc'对应的replaces就是 ['abc', 'bbc', 'cbc', ... , 'abx', ' aby', 'abz' ] ，一共包含78个词（26 × 3）。</p>
<p>　　（5）<strong>inserts</strong>：在word的邻近两位之间依次插入一个字母，所形成的所有新词。比如，'abc' 对应的inserts就是['aabc', 'babc', 'cabc', ..., 'abcx', 'abcy', 'abcz']，一共包含104个词（26 × 4）。</p>
</blockquote><p>最后，edit1()返回deletes、transposes、replaces、inserts的合集，这就是与word"编辑距离"等于1的所有词。对于一个n位的词，会返回54n+25个词。</p><p><strong>第七步，定义edit2()函数，用来生成所有与word的"编辑距离"为2的词语。</strong></p><blockquote>
<p>　　def edits2(word):</p>
<p>　　　　return set(e2 for e1 in edits1(word) for e2 in edits1(e1))</p>
</blockquote><p>但是这样的话，会返回一个 (54n+25) * (54n+25) 的数组，实在是太大了。因此，我们将edit2()改为known_edits2()函数，将返回的词限定为在文本库中出现过的词。</p><blockquote>
<p>　　def known_edits2(word):</p>
<p>　　　　return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in NWORDS)</p>
</blockquote><p><strong>第八步，定义correct()函数，用来从所有备选的词中，选出用户最可能想要拼写的词。</strong></p><blockquote>
<p>　　def known(words): return set(w for w in words if w in NWORDS)</p>
<p>　　def correct(word):</p>
<p>　　　　candidates = known([word]) or known(edits1(word)) or known_edits2(word) or [word]</p>
<p>　　　　return max(candidates, key=NWORDS.get)</p>
</blockquote><p>我们采用的规则为：</p><blockquote>
<p>　　（1）如果word是文本库现有的词，说明该词拼写正确，直接返回这个词；</p>
<p>　　（2）如果word不是现有的词，则返回"编辑距离"为1的词之中，在文本库出现频率最高的那个词；</p>
<p>　　（3）如果"编辑距离"为1的词，都不是文本库现有的词，则返回"编辑距离"为2的词中，出现频率最高的那个词；</p>
<p>　　（4）如果上述三条规则，都无法得到结果，则直接返回word。</p>
</blockquote><p><strong>至此，<a rel="external nofollow" target="_blank" href="http://pastebin.com/UVwuBrcs">代码</a>全部完成，合起来一共21行。</strong></p><blockquote>
<p>　　import re, collections</p>
<p>　　def words(text): return re.findall('[a-z]+', text.lower())</p>
<p>　　def train(features):</p>
<p>　　　　model = collections.defaultdict(lambda: 1)</p>
<p>　　　　for f in features:</p>
<p>　　　　　　model[f] += 1</p>
<p>　　　　return model</p>
<p>　　NWORDS = train(words(file('big.txt').read()))</p>
<p>　　alphabet = 'abcdefghijklmnopqrstuvwxyz'</p>
<p>　　def edits1(word):</p>
<p>　　　　splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]</p>
<p>　　　　deletes = [a + b[1:] for a, b in splits if b]</p>
<p>　　　　transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)&gt;1]</p>
<p>　　　　replaces = [a + c + b[1:] for a, b in splits for c in alphabet if b]</p>
<p>　　　　inserts = [a + c + b for a, b in splits for c in alphabet]</p>
<p>　　　　return set(deletes + transposes + replaces + inserts)</p>
<p>　　def known_edits2(word):</p>
<p>　　　　return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in NWORDS)</p>
<p>　　def known(words): return set(w for w in words if w in NWORDS)</p>
<p>　　def correct(word):</p>
<p>　　　　candidates = known([word]) or known(edits1(word)) or known_edits2(word) or [word]</p>
<p>　　　　return max(candidates, key=NWORDS.get)</p>
</blockquote><p>使用方法如下：</p><blockquote>
<p>　　&gt;&gt;&gt; correct('speling')</p>
<p>　　'spelling'</p>
<p>　　&gt;&gt;&gt; correct('korrecter')</p>
<p>　　'corrector'</p>
</blockquote><p><strong>四、缺陷</strong></p><p>我们使用的这种算法，有一些缺陷，如果投入生产环境，必须在这些方面加入改进。</p><p><strong>（1）文本库必须有很高的精确性，不能包含拼写错误的词。</strong></p><p>如果用户输入一个错误的拼法，文本库恰好包含了这种拼法，它就会被当成正确的拼法。</p><p><strong>（2）对于不包含在文本库中的新词，没有提出解决办法。</strong></p><p>如果用户输入一个新词，这个词不在文本库之中，就会被当作错误的拼写进行纠正。</p><p><strong>（3）程序返回的是"编辑距离"为1的词，但某些情况下，正确的词的"编辑距离"为2。</strong></p><p>比如，用户输入reciet，会被纠正为recite（编辑距离为1）,但用户真正想要输入的词是receipt（编辑距离为2）。也就是说，"编辑距离"越短越正确的规则，并非所有情况下都成立。</p><p><strong>（4）有些常见拼写错误的"编辑距离"大于2。</strong></p><p>这样的错误，程序无法发现。下面就是一些例子，每一行前面那个词是正确的拼法，后面那个则是常见的错误拼法。</p><blockquote>
<p>purple perpul<br />curtains courtens<br />minutes muinets<br />successful sucssuful<br />inefficient ineffiect<br />availability avaiblity<br />dissension desention<br />unnecessarily unessasarily<br />necessary nessasary<br />unnecessary unessessay<br />night nite<br />assessing accesing<br />necessitates nessisitates</p>
</blockquote><p><strong>（5）用户输入的词的拼写正确，但是其实想输入的是另一个词。</strong></p><p>比如，用户输入是where，这个词拼写正确，程序不会纠正。但是，用户真正想输入的其实是were，不小心多打了一个h。</p><p><strong>（6）程序返回的是出现频率最高的词，但用户真正想输入的是另一个词。</strong></p><p>比如，用户输入ther，程序会返回the，因为它的出现频率最高。但是，用户真正想输入的其实是their，少打了一个i。也就是说，出现频率最高的词，不一定就是用户想输入的词。</p><p><strong>（7）某些词有不同的拼法，程序无法辨别。</strong></p><p>比如，英国英语和美国英语的拼法不一致。英国用户输入'humur'，应该被纠正为'humour'；美国用户输入'humur'，应该被纠正为'humor'。但是，我们的程序会统一纠正为'humor'。</p><p>（完）</p><p>VIA&nbsp;<a rel="external nofollow" target="_blank" href="http://www.ruanyifeng.com/">http://www.ruanyifeng.com/</a>&nbsp;</p></div></div>
<script>var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-34802167-1']); _gaq.push(['_setDomainName', 'liuzhe.co']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })();</script></body>
</html>
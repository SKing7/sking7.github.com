<!doctype html>
<html>
<head>
<meta charset="utf-8"/>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>
    
      管道与Unix哲学 · 寂寞的宾狗
    
  </title>
<link rel="stylesheet" href="../css/article.css" />
</head>
<body>
<div class="m-content">
<h1>
    
      管道与Unix哲学 · 寂寞的宾狗
    
  </h1>
<article class="content">
        
<p>最近看到一篇文章关于Unix管道的，讲的非常透彻，所以这次依然做一个简单的<strong>翻译和解读</strong>~原文地址请戳<a href="http://blog.petersobot.com/pipes-and-filters">这里</a></p>

<p>下面正式开始~</p>

<!--more-->

<p>管道(Pipelines)是现代软件工程中一个非常有用架构模型，最早使用在Unix系统中，有句话是这么说的</p>

<blockquote>
  <p>如果说Unix是计算机文明中最伟大的发明，那么，Unix下的Pipe管道就是跟随Unix所带来的另一个伟大的发明</p>
</blockquote>

<p>管道所要解决的问题，还是软件设计中老生常谈的设计目标——高内聚，低耦合。它以一种“链式模型”来串接不同的程序或者不同的组件，让它们组成一条直线的工作流。这样给定一个完整的输入，经过各个组件的先后协同处理，得到唯一的最终输出。</p>

<p>如果你经常使用Unix的话，一定对管道符号<code>|</code>不陌生。那么，我们来看看下面这个例子</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">cat /usr/share/dict/words <span class="p">|</span>     <span class="c"># Read in the system's dictionary.</span>
grep purple <span class="p">|</span>                   <span class="c"># Find words containing 'purple'</span>
awk <span class="s1">'{print length($1), $1}'</span> <span class="p">|</span>  <span class="c"># Count the letters in each word</span>
sort -n <span class="p">|</span>                       <span class="c"># Sort lines ("${length} ${word}")</span>
tail -n <span class="m">1</span> <span class="p">|</span>                     <span class="c"># Take the last line of the input</span>
cut -d <span class="s2">" "</span> -f <span class="m">2</span> <span class="p">|</span>               <span class="c"># Take the second part of each line</span>
cowsay -f tux                   <span class="c"># Put the resulting word into Tux's mouth</span></code></pre></div>

<p>用<code>bash</code>运行上面的命令，最终会返回一只可爱的<code>Linux</code>小企鹅，并告诉你字典中包含<code>purple</code>最长的一个单词，看起来是下面这个样子</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">_____________ 
&lt; unimpurpled &gt;
 ------------- 
   <span class="se">\</span>
    <span class="se">\</span>
        .--.
       <span class="p">|</span>o_o <span class="p">|</span>
       <span class="p">|</span>:_/ <span class="p">|</span>
      //   <span class="se">\ \</span>
     <span class="o">(</span><span class="p">|</span>     <span class="p">|</span> <span class="o">)</span>
    /<span class="err">'</span><span class="se">\_</span>   _/<span class="sb">`</span><span class="se">\</span>
    <span class="se">\_</span>__<span class="o">)=(</span>___/</code></pre></div>



<p>上面看似简单的命令却执行了一个非常复杂的流程，当我们按下回车键时，下面的步骤依次执行</p>

<ol>
  <li><code>shell</code>会立即创建7个进程</li>
  <li>每个进程的标准输入(<code>stdin</code>)和标准输出(<code>stdout</code>)将被重定向到<code>shell</code>的内部缓存中(在我的机器上每个这样的缓存大小为512字节，你可以用<code>ulimit -a</code>命令来查看你自己机器上这个缓存的大小)</li>
  <li>源进程<code>cat</code>开始从文件中读取内容并输出到<code>stdout</code>。这个数据流通过第一个管道进入到第一个缓存中，而且很快就会到达缓存容量的上限。一旦到达这个上限，<code>cat</code>就会被它自己的<code>write(2)</code>所阻塞。这是管道的优点之一：<code>cat</code>的执行过程隐式的受管道数据处理的能力的控制。(有点类似<strong>协程</strong>的概念，这里每一个进程都充当了一个“协程”)</li>
  <li>接下来第一个过滤进程<code>grep</code>调用<code>read(2)</code>从它的<code>stdin</code>管道中读取数据。当<code>grep</code>进程刚被创建的时候，这个管道是空的(<code>cat</code>进程的输出数据还没有传输过来)，所以<code>grep</code>进程会被阻塞，直到有新数据到来。这里我们再一次看到了基于数据处理能力隐式执行控制。<code>grep</code>从读取的数据的每一行中进行匹配，并将匹配的单词输出到<code>grep</code>进程的<code>stdout</code>中，同样通过管道传送给下一个进程</li>
  <li><code>awk</code>进程的执行过程与<code>grep</code>类似。没有数据的时候<code>awk</code>进程将被阻塞，有新数据到来的时候，<code>awk</code>对数据进行处理并输出到<code>stdout</code>中</li>
  <li><code>sort</code>与之前两个进程稍有不同。因为<code>sort</code>涉及到排序，必须在完整的数据上执行。<code>sort</code>会把每次从<code>shell</code>缓存中读取的数据保存在磁盘上的一个缓存空间中。当<code>sort</code>的<code>stdin</code>关闭时(意味着没有更多新数据了)，<code>sort</code>会进行排序操作，并输出到<code>stdout</code></li>
  <li><code>tail</code>与<code>sort</code>类似，也是需要在完整的数据上执行。不过<code>tail</code>不需要占用太多的缓存空间，因为<code>tail</code>只关心输入的最后一行数据</li>
  <li><code>cut</code>又相当于一个过滤器，与<code>grep</code>和<code>awk</code>类似。</li>
  <li><code>cowsay</code>同样一直等待输入，计算输入的长度，并用ASCII码字符绘制出说话的<code>Linux</code>企鹅</li>
</ol>

<p>利用管道来执行这个任务非常简单，一个没有编程基础的人都可以轻松完成。每个步骤所用到的数据都经过了上一个任务的过滤，当前数据集在每一步都会改变。正如Unix哲学所倡导的</p>

<blockquote>
  <p>Do one thing, Do it well</p>
</blockquote>

<p>为了更直观的展示这个过程，我们把上述步骤画在一张图上</p>

<p><img src="http://bindog.qiniudn.com/pipes/pipeline_diagram.png" alt="pipeline_diagram" /></p>


<p>管道的另一个优点就是它天生的高性能。我们对上面的命令稍作修改以观察其中每一个过滤器组件的内存和CPU占用率</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">/usr/bin/time -l cat /usr/share/dict/words 2&gt; cat.time.txt <span class="p">|</span> 
/usr/bin/time -l grep purple 2&gt; grep.time.txt <span class="p">|</span>
/usr/bin/time -l awk <span class="s1">'{print length($1), $1}'</span> 2&gt; awk.time.txt <span class="p">|</span>
/usr/bin/time -l sort -n 2&gt; sort.time.txt <span class="p">|</span>
/usr/bin/time -l tail -n <span class="m">1</span> 2&gt; tail.time.txt <span class="p">|</span>
/usr/bin/time -l cut -d <span class="s2">" "</span> -f <span class="m">2</span> 2&gt; cut.time.txt <span class="p">|</span>
/usr/bin/time -l cowsay -f tux 2&gt; cowsay.time.txt</code></pre></div>

<p>(注意：如果你使用的是<code>Linux</code>，可以使用<code>-v</code>选项实现同样的效果。<code>2&gt; something.time.txt</code>会将<code>stderr</code>重定向到文件中)</p>

<p>在运行完上述命令后，通过查看输出文件里面的相关信息，我们可以画出下面几张图</p>

<p><img src="http://bindog.qiniudn.com/pipes/pipeline_graphs.png" alt="pipeline_graphs" /></p>

<ul>
  <li>其中内存占用最大的过滤器是<code>cowsay</code>，占用了<code>2,830,336</code>字节，因为它是用<code>Perl</code>实现的(在我的机器上仅启动<code>Perl</code>的解释器就要占用<code>1,126,400</code>字节的内存)，内存占用最小的是<code>tail</code>，只占用了<code>389,120</code>字节</li>
  <li>尽管我们的源文件(<code>/usr/share/dict/words</code>)有<code>2.4MB</code>，但是大部分的过滤器都没有占用大于源文件1/5的内存，这得益于我们之前所提到的：管道只保存它所能处理的最大数据量，一旦超过这个值，相关进程将被阻塞，直到下一级进程将数据取走并清空缓存。这个特性决定了管道是一个非常节省内存空间的轻量级解决方案，无论处理多大的文件，管道占用的都是一块恒定的内存空间</li>
  <li>注意到前两个进程<code>cat</code>和<code>grep</code>有大量自愿上下文切换(voluntary context switches)，这主要是由IO阻塞引起的(毕竟缓存大小只有512字节)。<code>cat</code>从磁盘上读取文件时必须将上下文切换到操作系统，然后将读取的内容输出到<code>stdout</code>，<code>grep</code>从管道读取数据时同样要进行上下文切换。而<code>ack</code>、<code>sort</code>、<code>tail</code>、<code>cut</code>并没有太多上下文切换的原因在于它们处理的数据量要小的多，<code>grep</code>已经替它们过滤了大量数据，实际交由<code>ack</code>处理的数据只有12行，任何一个缓存都可以装下这些数据</li>
  <li><code>cowsay</code>有许多非自愿上下文切换(involuntary context switches)，不过这并不是它所处理的数据太多引起的。前面提到了<code>cowsay</code>是用<code>Perl</code>实现的，效率与其他相比是较低的，因此这里较多的非自愿上下文切换是进程时间片(time quantum )耗尽引起的</li>
</ul>

<p>我们只是展示了一个简单的例子，不过设想一下，如果其中某些进程执行的是复杂的计算任务，那么它们将自动在多处理器上并行执行。这么来看的话管道的优势非常明显~</p>



<p>回顾一下管道的优点，省内存、省CPU时间，基于数据处理能力的隐式执行控制，方便快捷……既然管道有如此多的优点，为什么没有在实际中大规模应用呢？</p>

<p>原因在于异常处理，如果管道的某个中间环节出了问题，那么整个管道就彻底挂掉了。</p>

<p>我们对刚才那个例子稍作修改，加入一个自己用python实现的<code>fail.py</code>程序，它把<code>stdin</code>的内容直接输出到<code>stdout</code>中去，但是它有50%的概率产生异常</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">cat /usr/share/dict/words <span class="p">|</span>     <span class="c"># Read in the system's dictionary.</span>
grep purple <span class="p">|</span>                   <span class="c"># Find words containing 'purple'</span>
awk <span class="s1">'{print length($1), $1}'</span> <span class="p">|</span>  <span class="c"># Count the letters in each word</span>
sort -n <span class="p">|</span>                       <span class="c"># Sort lines ("${length} ${word}")</span>
python fail.py <span class="p">|</span>                <span class="c"># Play Russian Roulette with our data!</span>
tail -n <span class="m">1</span> <span class="p">|</span>                     <span class="c"># Take the last line of the input</span>
cut -d <span class="s2">" "</span> -f <span class="m">2</span> <span class="p">|</span>               <span class="c"># Take the second part of each line</span>
cowsay -f tux                   <span class="c"># Put the resulting word into Tux's mouth</span></code></pre></div>

<p><code>fail.py</code>的源码</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">]):</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">line</span><span class="p">:</span>
        <span class="k">break</span>  
    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span></code></pre></div>

<p>那么我们来看看异常产生时会发生什么事情。当<code>fail.py</code>在读取<code>stdin</code>之前就退出时，它的<code>stdin</code>和<code>stdout</code>管道就关闭了，这相当于把整个管道切成了两半，接下来就会产生一系列连锁反应</p>

<ol>
  <li><code>sort</code>进程会接收到一个<code>SIGPIPE</code>信号通知它的<code>stdout</code>管道被关闭了。此时<code>sort</code>可以选择立即处理这个<code>SIGPIPE</code>或者重新尝试<code>write(2)</code>，但是此时调用<code>write(2)</code>只能返回<code>-1</code>，因为<code>stdout</code>管道已被关闭。所以<code>sort</code>无法正常输出，只以选择退出，并关闭它的<code>stdin</code>管道，这又会导致<code>sort</code>之前的进程依次关闭退出(当然进程并非遇到<code>SIGPIPE</code>或者写错误就必须退出，但是这个例子中异常是由进程的输出管道被关闭引起的，所以除了退出没有其他办法)</li>
  <li><code>tail</code>进程同样收到一个<code>SIGPIPE</code>信号通知它的<code>stdin</code>管道被关闭，此时<code>tail</code>可以选择处理这个<code>SIGPIPE</code>信号或者忽略这个信号，但是无论怎样，它下一次调用<code>read(2)</code>时将会返回错误，而且无法与正常的流结束区分开来(因为同样都是没有新的数据了)，因此<code>tail</code>会认为这是正常的流结束标志，会在现有数据基础上进行操作，并将结果输出到<code>stdout</code></li>
  <li><code>cut</code>同样不会察觉有异常发生，会在<code>tail</code>提供的数据上正常执行</li>
  <li><code>cowsay</code>会输出在<code>python</code>发生异常之前的数据集中含<code>purple</code>且最长的单词</li>
</ol>

<p>结果是什么呢？</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">__________ 
&lt; repurple &gt;
 ---------- 
   <span class="se">\</span>
    <span class="se">\</span>
        .--.
       <span class="p">|</span>o_o <span class="p">|</span>
       <span class="p">|</span>:_/ <span class="p">|</span>
      //   <span class="se">\ \</span>
     <span class="o">(</span><span class="p">|</span>     <span class="p">|</span> <span class="o">)</span>
    /<span class="err">'</span><span class="se">\_</span>   _/<span class="sb">`</span><span class="se">\</span>
    <span class="se">\_</span>__<span class="o">)=(</span>___/</code></pre></div>

<p>企鹅说的不再是unimpurpled，而变成了repurple，这个结果是错误的！虽然其中一个过滤器发生了异常，我们还是得到结果了，只不过是一个错误的结果，但是更糟糕的事情是当我们查看管道的返回码时，得到了这样的结果</p>



<p><code>bash</code>显示管道正确执行了，这是由于<code>bash</code>把最后一个进程的返回码当作整个管道的状态码返回给我们。如果要查看管道中每一个进程的返回码，要使用到一个很少用到的<code>$PIPESTATUS</code>变量</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">bash-3.2<span class="nv">$ </span><span class="nb">echo</span> <span class="k">${</span><span class="nv">PIPESTATUS</span><span class="p">[*]</span><span class="k">}</span>
<span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">1</span> <span class="m">0</span> <span class="m">0</span> 0</code></pre></div>

<p>这个数组保存了管道中每一个进程的返回码，只有从这里我们才能发现管道中的一个过滤器发生了异常</p>

<p>这就是传统的Unix管道一个非常大的缺点，如果想在管道处理数据时探测异常需要用到带外数据(out-of-band)信号来检测异常，并将消息发到其他进程(如果你的过滤器有不止一个输入管道这是非常好实现的，但如果你使用的仅仅是Unix管道就比较困难了)</p>



<p>看完了上面的介绍，你可能会有下面的问题</p>

<blockquote>
  <p>管道在现实中如何使用呢？</p>

  <p>能否在我的web app中使用管道呢？</p>
</blockquote>

<p>这些对管道来说都不是问题，只要你的任务可以被划分为很小的部分而且处理时可以逐步完成就可以了。下面我们来看几个实例~</p>

<h2 id="section">音频转码</h2>
<p>假设你有许多<code>.flac</code>格式的文件——高品质音乐文件，你想把他们放到MP3里面去，但是它不支持<code>.flac</code>格式。而且由于某些原因，你的电脑上可用的RAM空间不超10M，这时该怎么办呢？你可以使用管道</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">ls *.flac <span class="p">|</span> 
<span class="k">while</span> <span class="nb">read </span>song
<span class="k">do</span> 
    flac -d <span class="s2">"$song"</span> --stdout <span class="p">|</span> 
    lame -V2 - <span class="s2">"$song"</span>.mp3
<span class="k">done</span></code></pre></div>

<p>这个命令比我们之前用到的更复杂一点，这里用到了内建的<code>bash</code>结构——<code>while</code>，从输入的每一行中读取文件名(从ls输出的管道中获取)，内层循环中调用了<code>flac</code>解码音频文件，然后调用<code>lame</code>将其编码为MP3格式。</p>

<p>这个管道的性能如何呢？在一个全部为<code>.flac</code>文件，总大小为115MB的文件夹中运行上述命令，只占用了<strong>1.3MB</strong>内存</p>

<h2 id="web-app">web app</h2>
<p>设想这样一个网页应用，用户提交了一个表单，现在你需要在后端对这个表单进行处理，涉及数据清洗，数据验证，最终保存为一个PDF文件(当然这个例子可能显得有些做作)。这些任务依然可以用管道来完成</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">my_webserver <span class="p">|</span> 
line_sanitizer <span class="p">|</span> 
verifier <span class="p">|</span> 
pdf_renderer</code></pre></div>

<p>当用户将表单提交到<code>my_webserver</code>，它会将这些数据转换为一行JSON并输出到<code>stdout</code>，假设这个JSON数据是这样的</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="p">{</span><span class="s">"name"</span><span class="p">:</span> <span class="s">"Raymond Luxury Yacht"</span><span class="p">,</span> <span class="s">"organization"</span><span class="p">:</span> <span class="s">"Flying Circus"</span><span class="p">}</span></code></pre></div>

<p>管道中的下一个进程<code>line_sanitizer</code>可以作如下处理</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
    <span class="n">obj</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>

    <span class="k">if</span> <span class="s">"Eric Idle"</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">[</span><span class="s">'name'</span><span class="p">]:</span>
        <span class="c"># Ignore forms submitted by Eric Idle.</span>
        <span class="k">continue</span>

    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span></code></pre></div>

<p>下一个进程验证用户填写的organization是否存在</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
    <span class="n">obj</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="n">org</span> <span class="o">=</span> <span class="n">obj</span><span class="p">[</span><span class="s">'organization'</span><span class="p">]</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"http://does.it/exist"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">org</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">resp</span><span class="o">.</span><span class="n">response_code</span> <span class="o">==</span> <span class="mi">404</span><span class="p">:</span>
        <span class="k">continue</span>

    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span></code></pre></div>

<p>最后一个进程把这些信息保存到PDF文件中</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">magical_pdf_writer_that_doesnt_exist</span> <span class="kn">as</span> <span class="nn">writer</span>

<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
    <span class="n">obj</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">write_to_file</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span></code></pre></div>

<p>不过还有一个问题没有解决，就是我们前面提到的异常处理。比如当某个用户使用了Eric Idle这个用户名或者填写了一个不存在的organization时，我们如何reject这次提交并告知用户错误信息呢？一个非常有Unix特色的方法就是使用<strong>命名管道(named pipe)</strong>来处理所有失败请求</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">mkfifo errors  <span class="c"># create a named pipe for our errors</span>

my_webserver <span class="p">|</span> 
line_sanitizer 2&gt; errors <span class="p">|</span> 
verifier 2&gt; errors <span class="p">|</span> 
pdf_renderer 2&gt; errors</code></pre></div>

<p>任何进程都可以从我们自定义的命名管道<code>errors</code>中读取数据，此外管道中的每个进程都可以把错误信息输出到命名管道<code>errors</code>中。我们还可以添加一个reader，当发生异常的时候从命名管道<code>errors</code>中读取信息并给我们发一封邮件</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">mkfifo errors              <span class="c"># create a named pipe for our errors</span>
email_on_error &lt; errors <span class="p">&amp;</span>  <span class="c"># add a reader to this pipe</span>

my_webserver <span class="p">|</span> 
line_sanitizer 2&gt; errors <span class="p">|</span> 
verifier 2&gt; errors <span class="p">|</span> 
pdf_renderer 2&gt; errors</code></pre></div>

<p>此时，<code>line_sanitizer</code>可以这样写</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
    <span class="n">obj</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>

    <span class="k">if</span> <span class="s">"Eric Idle"</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">[</span><span class="s">'name'</span><span class="p">]:</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>        
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span></code></pre></div>

<p>把这个流程也画成一张图，红色的线代表<code>stderr</code></p>

<p><img src="http://bindog.qiniudn.com/pipes/pipeline_stderr.png" alt="pipeline_stderr" /></p>



<p>Unix管道有很多优点，但也存在诸多不足。并非所有软件都能适用Unix管道模型，但是好在我们有替代方案</p>

<p>现在“工作队列”软件包近几年发展比较迅猛，有些可以支持简单的跨机器之间的FIFO队列。<a href="http://kr.github.io/beanstalkd/"><code>beanstalk</code></a>和<a href="http://kr.github.io/beanstalkd/"><code>celery</code></a>支持在任意进程间创建工作队列。这些都可以简单模拟传统Unix管道模型，而且由于可以在多台机器之间进行，也拥有分布式的优点。但是这些都只适用于异步的任务处理，它们的队列不会阻塞某个进程发送消息，我们前面提到的传统Unix管道模型中隐式的执行控制并没有体现出来，这些解决方案更像是消息系统或者工作队列而并非协程。</p>

<p>因此，我创建了一个基于<code>Redis</code>且同步的分布式管道库——<a href="http://github.com/psobot/pressure"><code>pressure</code></a>，<code>pressure</code>允许你在不同进程之间建立管道，并加入了管道缓存区的概念，而且支持跨多台机器使用。通过使用<code>Redis</code>作为稳定的消息代理，所有进程间通信都可以被<code>Redis</code>接管，能保证很好的操作系统和平台无关性。(<code>Redis</code>还拥有可靠性和可复用性等诸多优点)</p>

<p><code>pressure</code>是用<code>python</code>实现的，目前仍处于起步阶段。为了展示<code>pressure</code>的强大之处，我们用<code>pressure</code>自带的Unix管道适配器实现本文开始的那个例子。(<code>put</code>和<code>get</code>是用C实现的两个小程序，充当传统Unix管道和存放在<code>Redis</code>中分布式<code>pressure</code>队列之间的桥梁)</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Read in the system's dictionary</span>
cat /usr/share/dict/words <span class="p">|</span> ./put test_1 <span class="p">&amp;</span>

<span class="c"># Find words containing 'purple'</span>
./get test_1 <span class="p">|</span> grep purple <span class="p">|</span> ./put test_2 <span class="p">&amp;</span>

<span class="c"># Count the letters in each word</span>
./get test_2 <span class="p">|</span> awk <span class="s1">'{print length($1), $1}'</span> <span class="p">|</span> ./put test_3 <span class="p">&amp;</span>

<span class="c"># Sort lines</span>
./get test_3 <span class="p">|</span> sort -n <span class="p">|</span> ./put test_4 <span class="p">&amp;</span>

<span class="c"># Take the last line of the input</span>
./get test_4 <span class="p">|</span> tail -n <span class="m">1</span> <span class="p">|</span> ./put test_5 <span class="p">&amp;</span>

<span class="c"># Take the second part of each line</span>
./get test_5 <span class="p">|</span> cut -d <span class="s2">" "</span> -f <span class="m">2</span> <span class="p">|</span> ./put test_6 <span class="p">&amp;</span>

<span class="c"># Put the resulting word into Tux's mouth</span>
./get test_6 <span class="p">|</span> cowsay -f tux</code></pre></div>

<p>首先要说明的是这是一个非常慢的过程，整个过程结束时通过<code>Redis</code>发送的消息共有<code>235,912</code>条，这部分的时间开销就有将近4分钟(如果我们让<code>grep</code>紧接着<code>cat</code>执行，而不是先把数据放到<code>Redis</code>中，整个过程可以提速1200倍)，但是不管怎样，最终我们得到了一个正确的结果</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">_____________ 
&lt; unimpurpled &gt;
 ------------- 
   <span class="se">\</span>
    <span class="se">\</span>
        .--.
       <span class="p">|</span>o_o <span class="p">|</span>
       <span class="p">|</span>:_/ <span class="p">|</span>
      //   <span class="se">\ \</span>
     <span class="o">(</span><span class="p">|</span>     <span class="p">|</span> <span class="o">)</span>
    /<span class="err">'</span><span class="se">\_</span>   _/<span class="sb">`</span><span class="se">\</span>
    <span class="se">\_</span>__<span class="o">)=(</span>___/</code></pre></div>

<p><code>pressure</code>依然保持了传统Unix管道节省空间的特性，我们可以用<code>Redis</code>命令行工具查看内存使用情况</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>redis-cli info <span class="p">|</span> grep memory
used_memory:3126928
used_memory_human:2.98M
used_memory_rss:2850816
used_memory_peak:3127664
used_memory_peak_human:2.98M
used_memory_lua:31744</code></pre></div>

<p><code>pressure</code>仍在开发阶段，现在还不能大规模部署，希望大家都能来用一用，提出宝贵的建议~</p>



<p>到这里全文就结束了，下面还是谈谈我个人的感受吧~</p>

<ol>
  <li>以前对管道什么的还真不太了解，主要还是Unix、Linux系统用的太少了，但是读完这篇文章涨姿势了~</li>
  <li>管道的精髓不在于某个应用，而是它的哲学思想，”Do one thing, Do it well”，影响了一代又一代的软件架构，今天的云计算中依然可以看到它的身影</li>
  <li>原作者开发的<code>pressure</code>是一个非常有意义的探索，但能否在实际中大规模应用还有很长的路要走</li>
  <li><code>Redis</code>是一个非常强大的Key-Value存储系统，现在很多大型系统架构都在用~</li>
</ol>

<h2 id="section-1">扩展阅读</h2>



        </article></div>
<script>var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-34802167-1']); _gaq.push(['_setDomainName', 'liuzhe.co']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })();</script></body>
</html>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="keywords" content="web performance faster web sites high performance web sites website optimization best practices javascript css web development mobile">
<title>I  | High Performance Web Sites</title>
<link rel="stylesheet" type="text/css" media="all" href="http://www.stevesouders.com/blog/wp-content/themes/SteveSouders/style.css" />
<link rel="alternate" type="application/rss+xml" title="High Performance Web Sites &raquo; I &lt;3 image bytes Comments Feed" href="http://www.stevesouders.com/blog/2013/04/26/i/feed/" />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="http://www.stevesouders.com/blog/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="http://www.stevesouders.com/blog/wp-includes/wlwmanifest.xml" /> 
<link rel='prev' title='HTML5 VIDEO bytes on iOS' href='http://www.stevesouders.com/blog/2013/04/21/html5-video-bytes-on-ios/' />
<link rel='next' title='How fast are we going now?' href='http://www.stevesouders.com/blog/2013/05/09/how-fast-are-we-going-now/' />
<meta name="generator" content="WordPress 3.6.1" />
<link rel='canonical' href='http://www.stevesouders.com/blog/2013/04/26/i/' />
<link rel='shortlink' href='http://www.stevesouders.com/blog/?p=3536' />
<script type="text/javascript">
	window._wp_rp_static_base_url = 'http://dtmvdvtzf8rz0.cloudfront.net/static/';
	window._wp_rp_wp_ajax_url = "http://www.stevesouders.com/blog/wp-admin/admin-ajax.php";
	window._wp_rp_plugin_version = '2.6';
	window._wp_rp_post_id = '3536';
	window._wp_rp_num_rel_posts = '5';
</script>

<script>
(function(d, s) {
	var js = d.getElementsByTagName(s)[0],
		ln = d.createElement(s);
	ln.src = '//lognormal.net/boomerang/8fa4fc2785a82fae20c596ca4f45d1b218a9ab12ffef741d09b29532';
	js.parentNode.insertBefore(ln, js);
})(document, 'script');
</script>

<script type="text/javascript">
// GOOGLE ANALYTICS
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-15026169-1']);
_gaq.push(['_setSiteSpeedSampleRate', 100]);
_gaq.push(['_trackPageview']);

(function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
</script>
</head>

<body>
<div id="header">
	<div class="containerwrapper">
  		<h1 id="logo"><a href="http://stevesouders.com/"><span>SteveSouders.com</span></a></h1>
        <ul id="topnav">
        <li><a href="http://stevesouders.com/about.php">about</a></li>
        <li><a href="http://stevesouders.com/contact.php">contact</a></li>
        <li class="last"> <a href="http://twitter.com/#!/souders/"><img src="/images/twitter-icon.png" width=16 height=16 border=0 style="vertical-align: bottom;"></a>
        </ul>
	</div>    
</div>
<div id="contentWrapper" class="containerwrapper">
<div id="sidebar">
<div id="search-3" class="widget widget_search"><form role="search" method="get" id="searchform" class="searchform" action="http://www.stevesouders.com/blog/">
				<div>
					<label class="screen-reader-text" for="s">Search for:</label>
					<input type="text" value="" name="s" id="s" />
					<input type="submit" id="searchsubmit" value="Search" />
				</div>
			</form></div><div id="custom-recent-posts-3" class="widget custom-recent-posts"><h3 class="blockheader">Most Recent Posts</h3>		<ul style="list-style-type: none; margin-left: 20px; text-indent: -20px;">
        		<li><a href="http://www.stevesouders.com/blog/2013/09/05/domain-sharding-revisited/" rel="bookmark">Domain Sharding revisited</a></li>
				<li><a href="http://www.stevesouders.com/blog/2013/08/27/web-performance-for-the-future/" rel="bookmark">Web performance for the future</a></li>
				<li><a href="http://www.stevesouders.com/blog/2013/07/16/activetable-bookmarklet/" rel="bookmark">ActiveTable bookmarklet</a></li>
				<li><a href="http://www.stevesouders.com/blog/2013/07/15/twitter-widget-update/" rel="bookmark">Twitter widget update</a></li>
				<li><a href="http://www.stevesouders.com/blog/2013/06/16/browser-busy-indicators/" rel="bookmark">Browser Busy Indicators</a></li>
				</ul>
		<a href="http://www.stevesouders.com/blog/archives/">View Archive</a></div><div id="text-3" class="widget widget_text"><h3 class="blockheader">Feeds</h3>			<div class="textwidget"><a href="http://www.stevesouders.com/blog/feed/"><img src="/blog/wp-content/uploads/2011/02/feed.png" width="10" height="10" /> </a><a href="http://www.stevesouders.com/blog/feed/">Posts</a><br />
<a href="http://www.stevesouders.com/blog/comments/feed/"><img src="/blog/wp-content/uploads/2011/02/feed.png" width="10" height="10" /> </a><a href="http://www.stevesouders.com/blog/comments/feed/">Comments</a></li></div>
		</div>        
</div><div id="content">



		<div id="post-3536" class="post-3536 post type-post status-publish format-standard hentry category-browsers category-javascript category-performance category-uncategorized category-web-development tag-preloader tag-responsive-images">
        	            	<h1>I <3 image bytes</h1>
            
			<p class="meta">April 26, 2013 10:08 am | <a href="http://www.stevesouders.com/blog/2013/04/26/i/#comments" title="Comment on I ">17 Comments</a></p><!-- .entry-meta -->

			<p>Much of my work on web performance has focused on JavaScript and CSS, starting with the early rules <a href="http://developer.yahoo.com/blogs/ydn/high-performance-sites-rule-6-move-scripts-bottom-7200.html">Move Scripts to the Bottom</a> and <a href="http://developer.yahoo.com/blogs/ydn/high-performance-sites-rule-5-put-stylesheets-top-7197.html">Put Stylesheets at the Top</a> from back in 2007(!). To emphasize these best practices I used to say, &#8220;JS and CSS are the most important bytes in the page&#8221;.</p>
<p>A few months ago I realized that wasn&#8217;t true. <em>Images are the most important bytes in the page.</em></p>
<p>My focus on JS and CSS was largely motivated by the desire to get the images downloaded as soon as possible. Users see images. They don&#8217;t <em>see</em> JS and CSS. It is true that JS and CSS affect what is seen in the page, and even whether and how images are displayed (e.g., JS photo carousels, and CSS background images and media queries). But my realization was JS and CSS are the means by which we get to these images. During page load we want to get the JS and CSS out of the way as quickly as possible so that the images (and text) can be shown.</p>
<p><em>My main motivation for optimizing JS and CSS is to get rendering to happen as quickly as possible.</em></p>
<h3>Rendering starts very late</h3>
<p>With this focus on rendering in mind, I went to the <a href="http://httparchive.org/">HTTP Archive</a> to see how quickly we&#8217;re getting pages to render. The HTTP Archive runs on top of <a href="http://www.webpagetest.org/">WebPagetest</a> which reports the following time measurements:</p>
<ul>
<li>time-to-first-byte (TTFB) &#8211; When the first packet of the HTML document arrives.</li>
<li>start render &#8211; When the page starts rendering.</li>
<li>onload &#8211; When window.onload fires.</li>
</ul>
<p>I extracted the 50th and 90th percentile values for these measurements across the world&#8217;s top 300K URLs. As shown, <em>nothing is rendered for the first third of page load time!</em><i><br />
</i></p>
<table class="basictable">
<tbody>
<tr>
<td class="label" colspan="4">Table 1. Time milestones during page load</td>
</tr>
<tr>
<th></th>
<th>TTFB</th>
<th>start render</th>
<th>onload</th>
</tr>
<tr>
<td class="txt">50th percentile</td>
<td class="num">610 ms</td>
<td class="num">2227 ms</td>
<td class="num">6229 ms</td>
</tr>
<tr>
<td class="txt">90th percentile</td>
<td class="num">1780 ms</td>
<td class="num">5112 ms</td>
<td class="num">15969 ms</td>
</tr>
</tbody>
</table>
<h3><span style="font-size: 1.17em;">Preloading</span></h3>
<p>The fact that rendering doesn&#8217;t start until the page is 1/3 into the overall page load time is eye-opening. Looking at both the 50th and 90th percentile stats from the HTTP Archive, rendering starts ~32-36% into the page load time. It takes ~10% of the overall page load time to get the first byte. Thus, for ~22-26% of the page load time the browser has bytes to process but nothing is drawn on the screen. During this time the browser is typically downloading and parsing scripts and stylesheets &#8211; both of which block rendering on the page.</p>
<p>It used to be that the browser was largely idle during this early loading phase (after TTFB and before start render). That&#8217;s because when an older browser started downloading a script, <a title="High Performance Web Sites: Rule 6  Move Scripts to the Bottom" href="http://developer.yahoo.com/blogs/ydn/high-performance-sites-rule-6-move-scripts-bottom-7200.html">all other downloads were blocked</a>. This is still visible in <a title="Browserscope" href="http://www.browserscope.org/?category=network&amp;v=1&amp;ua=IE%206,IE%207,IE%208,IE%209,IE%2010">IE 6&amp;7</a>. Browser vendors realized that while it&#8217;s true that constructing the DOM has to wait for a script to download and execute, there&#8217;s no reason other resources deeper in the page couldn&#8217;t be <em>fetched</em> in parallel. Starting with IE 8 in 2009, browsers started looking past the currently downloading script for other resources (i.e, SCRIPT, IMG, LINK, and IFRAME tags) and <em>preloading</em> those requests in parallel. One study showed preloading makes <a title="The WebKit PreloadScanner" href="http://gent.ilcore.com/2011/01/webkit-preloadscanner.html">pages load ~20% faster</a>. Today, all major browsers support preloading. In these <a href="http://www.browserscope.org/?category=network&amp;v=1&amp;ua=Chrome%202,Firefox%202,IE%208,iPhone%202,Opera%2012,Opera%20Mobile%2010,Safari%201">Browserscope results</a> I show the earliest version of each major browser where preloading was first supported.</p>
<p>(As an aside, I think preloading is the single biggest performance improvement browsers have ever made. Imagine today, with the abundance of scripts on web pages, what performance would be like if each script was downloaded sequentially and blocked all other downloads.)</p>
<h3>Preloading and responsive images</h3>
<p>This ties back to this <a href="https://twitter.com/grigs/status/327429827726561280">tweet from Jason Grigsby</a>:</p>
<blockquote><p>I’ll be honest. I’m tired of pushing for resp images and increasingly inclined to encourage devs to use JS to simply break pre-loaders.</p></blockquote>
<p>The &#8220;resp images&#8221; Jason refers to are techniques by which image requests are generated by JavaScript. This is generally used to adapt the size of images for different screen sizes. One example is <a href="https://github.com/scottjehl/picturefill">Picturefill</a>. When you combine &#8220;pre-loaders&#8221; and &#8220;resp images&#8221; an issue arises &#8211; the preloader looks ahead for IMG tags and fetches their SRC, but responsive image techniques typically don&#8217;t have a SRC, or have a stub image such as a 1&#215;1 transparent pixel. This defeats the benefits of preloading for images. So there&#8217;s a tradeoff:</p>
<ul>
<li><span style="line-height: 13px;">Don&#8217;t use responsive images so that the preloader can start downloading images sooner, but the images might be larger than needed for the current device and thus take longer to download (and cost more for limited cellular data plans).</span></li>
<li>Use responsive images which doesn&#8217;t take advantage of preloading which means the images are loaded later after the required JS is downloaded and executed, and the IMG DOM elements have been created.</li>
</ul>
<p>As Jason says in a follow-up <a href="https://twitter.com/grigs/status/327430930895609858">tweet</a>:</p>
<blockquote><p>The thing that drives me nuts is that almost none of it has been tested. Lots of gospel, not a lot of data.</p></blockquote>
<p>I don&#8217;t have any data comparing the two tradeoffs, but the HTTP Archive data showing that rendering doesn&#8217;t start until 1/3 into page load is telling. It&#8217;s likely that rendering is being blocked by scripts, which means the IMG DOM elements haven&#8217;t been created yet. So at some point after the 1/3 mark the IMG tags are parsed and at some point after that the responsive image JS executes and starts downloading the necessary images.</p>
<p>In my opinion, this is too late in the page load process to initiate the image requests, and will likely cause the web page to render later than it would if the preloader was used to download images. Again, I don&#8217;t have data comparing the two techniques. Also, I&#8217;m not sure how the preloader works with the responsive image techniques done via markup. (Jason has a blog post that touches on that, <a href="http://blog.cloudfour.com/the-real-conflict-behind-picture-and-srcset/">The real conflict behind &lt;picture&gt; and @srcset</a>.)</p>
<p>Ideally we&#8217;d have a responsive image solution in markup that would work with preloaders. Until then, I&#8217;m nervous about recommending to the dev community at large to move toward responsive images at the expense of defeating preloading. I expect browsers will add more benefits to preloading, and I&#8217;d like websites to be able to take advantage of those benefits both now and in the future.</p>

<div class="wp_rp_wrap  wp_rp_momma" id="wp_rp_first"><div class="wp_rp_content"><h3 class="related_post_title">Related Posts</h3><ul class="related_post wp_rp" style="visibility: visible"><li ><a href="http://www.stevesouders.com/blog/2009/04/27/loading-scripts-without-blocking/" class="wp_rp_title">Loading Scripts Without Blocking</a></li><li ><a href="http://www.stevesouders.com/blog/2012/12/03/the-perception-of-speed/" class="wp_rp_title">The Perception of Speed</a></li><li ><a href="http://www.stevesouders.com/blog/2010/12/06/evolution-of-script-loading/" class="wp_rp_title">Evolution of Script Loading</a></li><li ><a href="http://www.stevesouders.com/blog/2010/02/12/5e-speculative-background-images/" class="wp_rp_title">5e speculative background images</a></li><li ><a href="http://www.stevesouders.com/blog/2010/02/07/browser-script-loading-roundup/" class="wp_rp_title">Browser script loading roundup</a></li></ul><div class="wp_rp_footer"><a class="wp_rp_backlink" target="_blank" rel="nofollow" href="http://www.zemanta.com/?wp-related-posts">Zemanta</a></div></div></div>
            
            			
		</div><!-- #post-## -->


		
			<div id="comments">

			<h3 id="comments-title">17 Responses to <em>I <3 image bytes</em></h3>


			<ol class="commentlist">
				<li class="comment even thread-even depth-1" id="li-comment-60032">
<div id="comment-60032">
<p class="comment-metadata">
<strong><a href='http://aaronfranks.com' rel='external nofollow' class='url'>Aaron</a></strong> | 26-Apr-13 at 11:12 am | <a href="http://www.stevesouders.com/blog/2013/04/26/i/#comment-60032">Permalink</a> |  </p>


<p>The tweet about &#8220;using JS to break preloaders&#8221; reminds me of mobify.js (<a href="http://www.mobify.com/mobifyjs/" rel="nofollow">http://www.mobify.com/mobifyjs/</a>). Unfortunately it requires a script in the , but can rewrite images and other resources before the browser loads them. Haven&#8217;t used it, but learned about it recently and the approach looks promising.</p>
</div>
</li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="li-comment-60033">
<div id="comment-60033">
<p class="comment-metadata">
<strong><a href='http://aaronfranks.com' rel='external nofollow' class='url'>Aaron</a></strong> | 26-Apr-13 at 11:13 am | <a href="http://www.stevesouders.com/blog/2013/04/26/i/#comment-60033">Permalink</a> |  </p>


<p>^ should read: &#8220;Unfortunately it requires a script in the *head tag*, &#8230;&#8221;</p>
</div>
</li><!-- #comment-## -->
<li class="comment even thread-even depth-1" id="li-comment-60034">
<div id="comment-60034">
<p class="comment-metadata">
<strong><a href='http://www.brettjankord.com' rel='external nofollow' class='url'>Brett Jankord</a></strong> | 26-Apr-13 at 11:29 am | <a href="http://www.stevesouders.com/blog/2013/04/26/i/#comment-60034">Permalink</a> |  </p>


<p>One technique that I really like for resp. images that I *think* works well with the preloader is the technique Guy Podjarny&#8217;s talked about in his post: Introducing LQIP – Low Quality Image Placeholders (<a href="http://www.guypo.com/feo/introducing-lqip-low-quality-image-placeholders/" rel="nofollow">http://www.guypo.com/feo/introducing-lqip-low-quality-image-placeholders/</a>)</p>
<p>No doubt, its not a perfect solution, but its one that I&#8217;ve found useful. Ideally browsers would implement the proposed picture element and build their APIs and preload scanner to work w/ this new element.</p>
</div>
</li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="li-comment-60035">
<div id="comment-60035">
<p class="comment-metadata">
<strong><a href='http://andyhume.net' rel='external nofollow' class='url'>Andy Hume</a></strong> | 26-Apr-13 at 12:47 pm | <a href="http://www.stevesouders.com/blog/2013/04/26/i/#comment-60035">Permalink</a> |  </p>


<p>It&#8217;s not a binary decision either. You can choose to load the most important images via the pre-parser and defer other less important imagery to load via JavaScript.</p>
<p>I think this is best expressed by Paul Lloyd&#8217;s presentation at Responsiveconf a few months ago:</p>
<p><a href="https://speakerdeck.com/paulrobertlloyd/the-edge-of-the-web?slide=22" rel="nofollow">https://speakerdeck.com/paulrobertlloyd/the-edge-of-the-web?slide=22</a></p>
<p>The BBC mobile site does a good job of this:</p>
<p><a href="https://speakerdeck.com/paulrobertlloyd/the-edge-of-the-web" rel="nofollow">https://speakerdeck.com/paulrobertlloyd/the-edge-of-the-web</a></p>
</div>
</li><!-- #comment-## -->
<li class="comment even thread-even depth-1" id="li-comment-60036">
<div id="comment-60036">
<p class="comment-metadata">
<strong><a href='http://blog.cloudfour.com' rel='external nofollow' class='url'>Jason Grigsby</a></strong> | 26-Apr-13 at 1:04 pm | <a href="http://www.stevesouders.com/blog/2013/04/26/i/#comment-60036">Permalink</a> |  </p>


<p>Thanks Steve for taking the time to test and write this up. My tweet was a obvious moment of frustration. I haven&#8217;t been advocating breaking the pre-parser and in several conversations have been cautioning against it based on the feedback that you&#8217;ve given in the past.</p>
<p>That said, I do feel there is a big disconnect between what browser implementers are interested in pursuing (e.g., client hints using device widths) and what people trying to make responsive design see as the true problem we’re trying to solve (e.g., element queries).</p>
<p>I rarely get the sense from implementers and people working on standards that they really &#8220;get&#8221; what people are trying to accomplish with images in responsive designs. I will acknowledge that the Internet is a poor medium to convey the types of feedback that we need to know that someone has truly understood what we&#8217;re saying. So it is entirely possible that they do get it, but disagree or feel it isn&#8217;t possible.</p>
<p>So there is still a part of me that feels like we should just build solutions that solve our problems, take the performance hit, and then let the adoption of those approaches prove to implementors that some rethinking needs to be done.</p>
<p>And I believe this is already happening. The BBC and Guardian are doing it. Akamai sells an FEO approach that is based on wrestling control of image loading away from the pre-parser by replacing all imgs with a data uri transparent gif and then inserting the proper image source via JavaScript. Given Akamai&#8217;s marketshare and the number of large companies that are struggling with responsive images, that solution alone could break pre-parsing on a large number of sites.</p>
<p>Which leads me to wonder, is it worth our while to continue to try to convince skeptical implementors or should we simply promote more solutions like what BBC, Guardian and Akamai are doing? Which is a quicker path to getting a long term solution to the problem?</p>
<p>Maybe some short-term breaking of things is a necessary step to get things moving forward. That&#8217;s the the conclusion I&#8217;ve come to except in my moments of despair—the tweet you saw was one of those moments—but it is crossing my mind with increasing frequency.</p>
</div>
</li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="li-comment-60037">
<div id="comment-60037">
<p class="comment-metadata">
<strong><a href='http://blog.cloudfour.com' rel='external nofollow' class='url'>Jason Grigsby</a></strong> | 26-Apr-13 at 1:24 pm | <a href="http://www.stevesouders.com/blog/2013/04/26/i/#comment-60037">Permalink</a> |  </p>


<p>Argh, I kept rewriting that last sentence trying to get the tone right and still managed to end up with a broken and incoherent sentence.</p>
<p>What I was trying to say is that I haven&#8217;t yet concluded that we need to take this approach, but I find myself pondering which approach would get quicker results with increasing frequency.</p>
</div>
</li><!-- #comment-## -->
<li class="comment byuser comment-author-sowrock bypostauthor even thread-even depth-1 author" id="li-comment-60038">
<div id="comment-60038">
<p class="comment-metadata">
<strong><a href='http://stevesouders.com' rel='external nofollow' class='url'>Steve Souders</a></strong> | 26-Apr-13 at 2:06 pm | <a href="http://www.stevesouders.com/blog/2013/04/26/i/#comment-60038">Permalink</a> |  </p>


<p>Brett: Yes, Guypo&#8217;s (Akamai&#8217;s) LQIP would work with today&#8217;s preloaders.</p>
<p>Jason: It was a good, necessary tweet. Everyone needs to get more invested. It caught my eye, and I&#8217;m sure it caught the eye of browser developers. I&#8217;m nervous about recommending techniques that make performance worse &#8211; but I&#8217;m biased. Akamai&#8217;s FEO approach (LQIP) works with plain IMG tags &#8211; so it takes advantage of the preloader. (Or is there another technique you&#8217;re referring to?) Before we advocate breaking things I&#8217;d like to have a Responsive Images Summit with web devs and browser devs and see if we can&#8217;t find common ground. You and I had a long email thread on the alternatives, and I still wasn&#8217;t closer to see a clear solution.</p>
</div>
</li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="li-comment-60039">
<div id="comment-60039">
<p class="comment-metadata">
<strong><a href='http://blog.cloudfour.com' rel='external nofollow' class='url'>Jason Grigsby</a></strong> | 26-Apr-13 at 2:25 pm | <a href="http://www.stevesouders.com/blog/2013/04/26/i/#comment-60039">Permalink</a> |  </p>


<p>The Akamai technique I&#8217;m talking about isn&#8217;t the LQIP that Guy has blogged about. As far as I can tell, the technique I saw is being used for both their responsive images and their on-demand image loading solutions that are options within the FEO package. I&#8217;m unclear where LQIP fits in the offering.</p>
<p>For responsive images, Akamai reads the markup of the page and replaces any links to images with data uris. You can see this in action on Guy&#8217;s site:<br />
<a href="http://www.guypo.com/uncategorized/real-world-rwd-performance-take-2/" rel="nofollow">http://www.guypo.com/uncategorized/real-world-rwd-performance-take-2/</a></p>
<p>A typical img tag in his source looks like this:</p>
<p>img class=&#8221;alignnone  wp-image-3380&#8243; alt=&#8221;2013-page-size-per-resolution&#8221; src=&#8221;data:image/gif;base64,R0lGODlhAQABAID/AMDAwAAAACH5BAEAAAAALAAAAAABAAEAQAICRAEAOw==&#8221; blzsrc=&#8221;http://www.guypo.com/wp-content/uploads/2013/03/2013-page-size-per-resolution.png&#8221; blzjit=&#8221;1&#8243; width=&#8221;511&#8243; height=&#8221;336&#8243;</p>
<p>But when the JS executes, it replaces the placeholder image with a link to the correct image. The DOM of the rendered page shows:<br />
img class=&#8221;alignnone  wp-image-3381&#8243; alt=&#8221;2013-page-size-small-vs-big&#8221; src=&#8221;http://www.guypo.com/wp-content/uploads/2013/03/2013-page-size-small-vs-big1.png&#8221; blzsrc=&#8221;http://www.guypo.com/wp-content/uploads/2013/03/2013-page-size-small-vs-big1.png&#8221; blzjit=&#8221;1&#8243; width=&#8221;512&#8243; height=&#8221;447&#8243;</p>
<p>Unfortunately, most of the examples I have of Akamai&#8217;s FEO implementation are not responsive designs so I can&#8217;t point to this technique being used for responsive images, but as far as I understand, this is the approach used for any clients that sign up for the responsive images portion of the FEO solution.</p>
</div>
</li><!-- #comment-## -->
<li class="comment even thread-even depth-1" id="li-comment-60043">
<div id="comment-60043">
<p class="comment-metadata">
<strong>Guypo</strong> | 26-Apr-13 at 5:20 pm | <a href="http://www.stevesouders.com/blog/2013/04/26/i/#comment-60043">Permalink</a> |  </p>


<p>First off, to clarify re Akamai&#8217;s FEO: We have quite a few image related optimization, but two very commonly used ones are Responsive Images and Images On-Demand (only load images in the visible area, load others as they scroll into view). Both of those indeed use a script loader for images, breaking the pre-parser. It&#8217;s a very smart script loader, which kicks in early and squeezes the most out of the browser, but there&#8217;s no ignoring the fact it breaks the pre-parser.</p>
<p>It&#8217;s worth noting that we do compensate for that a bit with other optimizations like DNS prefetching (something the pre-parser may have done) and by making scripts and CSS async (if the scripts on the page don&#8217;t block the parser, the pre-parser is less critical), but even without those we see huge value in these optimizations. </p>
<p>While I didn&#8217;t collect broad data across many websites, I can say my experience shows the vast majority of pages &#8211; especially ones where at least 50% of the page is &#8220;below the fold&#8221; &#8211; benefit more from lazy loading images than from the pre-parser. The extra cost of downloading many images that aren&#8217;t actually needed (at least at first), and of those contending for bandwidth with what DOES need to get render far outweighs the value from what I can tell.</p>
<p>In an old presentation of mine I show examples on mobile websites (Walmart &amp; MSNBC&#8217;s sites at the time), where load times were drastically improved thanks to that optimization alone. That type of impact is quite common. Here&#8217;s the deck (slides 19-21): <a href="http://www.slideshare.net/guypod/unravelling-mobile-web-performance/19/" rel="nofollow">http://www.slideshare.net/guypod/unravelling-mobile-web-performance/19/</a></p>
<p>One disclaimer on this topic: Today, the pre-parser offers relatively little value to images, because CSS and JS block the download of those images. However, in a SPDY or HTTP 2 world, it&#8217;s possible this equation would change. Hopefully by then we&#8217;ll have browser support for capabilities like the picture element or img defer (<a href="https://www.w3.org/Bugs/Public/show_bug.cgi?id=17842" rel="nofollow">https://www.w3.org/Bugs/Public/show_bug.cgi?id=17842</a>), and won&#8217;t need to face the dilema.</p>
</div>
</li><!-- #comment-## -->
<li class="comment byuser comment-author-sowrock bypostauthor odd alt thread-odd thread-alt depth-1 author" id="li-comment-60044">
<div id="comment-60044">
<p class="comment-metadata">
<strong><a href='http://stevesouders.com' rel='external nofollow' class='url'>Steve Souders</a></strong> | 26-Apr-13 at 5:32 pm | <a href="http://www.stevesouders.com/blog/2013/04/26/i/#comment-60044">Permalink</a> |  </p>


<p>Guypo: Thanks for commenting! Is &#8220;Responsive Images&#8221; different from LQIP? Do you recommend people do both? If not, which one do you recommend? Seems like the best solution would be to do the first N images (assumed to be above-the-fold) as IMG to take advantage of the preloader, and
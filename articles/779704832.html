<!doctype html>
<html>
<head>
<meta charset="utf-8"/>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>The JavaScript Packaging Problem</title>
<link rel="stylesheet" href="../css/article.css" />
</head>
<body>
<div class="m-content">
<h1>The JavaScript Packaging Problem</h1>
<div>
    <div class="page-container"><span>
      </span><span>

      </span><div class="page-content-container"><span>
        </span><div class="page-content"><span>
          
            </span><span>
          

          
</span><p>
  Posted on November 29, 2014
</p><span>


</span><div class="post"><span>

</span><html><body>
<p><img src="http://jamie-wong.com/images/14-11-28/jspackaging.png" alt="JavaScript Packaging" /></p>

<p>I’ve been working on making Khan Academy’s JavaScript safer and faster since I joined as a full time software engineer back in July.</p>

<p>There’s a lot of ground to cover, so let’s ignore module systems, minification, code maintainability, and just focus on the problem of delivery performance.</p>

<p>Here’s the problem definition: you have a whole bunch of JavaScript that you want people to download on your website. How do you get said JavaScript from your server to your users' browsers? Your goal is to get this to happen as fast as possible.</p>

<p>Here’s the setup: you have a website with a whole bunch of pages. There is some amount of JavaScript shared by all of those pages, some more that’s shared by some of those pages, and some that’s only used on one of those pages.</p>

<p>For the sake of discussion, let’s use an incredibly simplified version of Khan Academy: there are video pages, exercise pages, and a home page.</p>

<p>Here’s a breakdown of which JavaScript source files are needed on each page:</p>

<p><img src="http://jamie-wong.com/images/14-11-28/js-setup.png" alt="The Setup" /></p>

<a name="Solution.1:.One.Script.Tag.Per.Source.File"></a>


<p>The easiest and most obvious solution looks like this:</p>

<pre><code>&lt;!doctype html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Video Page&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;!-- Server rendered video page content goes here ... -&gt;
    &lt;script src="/js/jquery.js"&gt;&lt;script&gt;
    &lt;script src="/js/underscore.js"&gt;&lt;/script&gt;
    &lt;script src="/js/react.js"&gt;&lt;/script&gt;
    &lt;script src="/js/sidebar.js"&gt;&lt;/script&gt;
    &lt;script src="/js/video-player.js"&gt;&lt;/script&gt;
    &lt;script src="/js/discussion.js"&gt;&lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>And then on the homepage, you’d have:</p>

<pre><code>    &lt;script src="/js/jquery.js"&gt;&lt;script&gt;
    &lt;script src="/js/underscore.js"&gt;&lt;/script&gt;
    &lt;script src="/js/homepage.js"&gt;&lt;/script&gt;
</code></pre>

<p>This is by far the simplest solution because it requires no fancy build system
like <a href="http://gruntjs.com/">Grunt</a> or <a href="http://gulpjs.com/">gulp</a> - you can just serve your JS directly from disk.
You’re going to want to have a build step anyway to do minification though, so
this isn’t a huge advantage.</p>

<a name="Cache.Performance"></a>
<h2>Cache Performance</h2>

<p>On the upside, this solution gives excellent cache performance. Each one of the
files can be separately cached, so changing one of your JS files will require
users to download only the things that changed since the last time they were
there <sup id="fnref:1"><a href="http://jamie-wong.com/2014/11/29/the-js-packaging-problem/#fn:1" rel="footnote">1</a></sup>. This is especially attractive because the biggest files, like
jQuery, are unlikely to change frequently.</p>

<p>Even better, if you need different JS files on different pages on your site, you
only have to download the bits of that page that you didn’t already get from
visiting other pages. For instance, if you went from the homepage to the video
page, you’d already have <code>jquery.js</code> and <code>underscore.js</code> in your cache.</p>

<a name="Network.Performance"></a>
<h2>Network Performance</h2>

<p>On the major downside, this is a ton of network traffic. If you have 10 JS
script files on your page, then you’re firing 10 HTTP requests to get those 10
files from server to browser. Each of these has overhead, and requires a round
trip to the server. Establishing connections can be slow, and each connection
undergoes <a href="http://en.wikipedia.org/wiki/Slow-start">TCP Slow-start</a>, meaning that it doesn’t reach full speed until
after a few round trips<sup id="fnref:2"><a href="http://jamie-wong.com/2014/11/29/the-js-packaging-problem/#fn:2" rel="footnote">2</a></sup>. Downloading ten 20kB files is a great deal slower
than downloading one 200kB file over HTTP because of this.</p>

<p>These problems are <a href="http://blog.cloudflare.com/what-makes-spdy-speedy/">largely mitigated</a> by <a href="http://en.wikipedia.org/wiki/SPDY">SPDY</a>, and support for SPDY is
rising, but it’s not good enough yet (<a href="http://caniuse.com/#feat=spdy">about 75%</a> as of this post) that we
can just completely ignore problems in HTTP.</p>

<a name="Compression"></a>
<h2>Compression</h2>

<p>When you’re sending any plaintext assets (HTML, JS, CSS, etc.) from the server,
you should be compressing those assets to send fewer bytes over the network.
<a href="http://betterexplained.com/articles/how-to-optimize-your-site-with-gzip-compression/">gzip</a> is the normal solution. By serving each file separately from the
server, we’re losing out on potential compression benefits.</p>

<p>As a test, I compared gzipping 60 JS files from one of Khan Academy’s folders
and then concatenating the results vs. concatenating and gzipping after.</p>

<p>Concatenate then compress: ~82kB</p>

<pre><code>$ cat *.js | gzip -c | wc -c
   84015
</code></pre>

<p>Compress then concatenate: ~98kB</p>

<pre><code>$ for i in *.js; do gzip -c $i; done | wc -c
   99997
</code></pre>

<p>Summary of One Script Tag Per Source File:</p>

<ul>
<li><span>Downloads only what is needed</span></li>
<li><span>High cache hit rate between page types</span></li>
<li><span>High cache hit rate between deploys</span></li>
<li><span>Many HTTP round trips</span></li>
<li><span>Poor Compression</span></li>
</ul>


<a name="Solution.2:.One.Big.JS.File"></a>


<p>When you see poor compression and the many HTTP round trips problems, the next
most obvious thing might be to concatenate absolutely all of your JS together.
Diagramatically, this would look like this:</p>

<p><img src="http://jamie-wong.com/images/14-11-28/one-big-file.png" alt="One Big File" /></p>

<p>And then every single one of your HTML files would have this:</p>

<pre><code>    &lt;script src="/build/js/khan-academy.js"&gt;&lt;/script&gt;
</code></pre>

<p>While this does offer better compression and fewer HTTP round trips, we have two
new problems. The first is that we’re now downloading potentially WAY more stuff
on a page than we actually need.</p>

<p>For instance, to load up the homepage of the site, you now need to download all
of the source of <code>react.js</code> and <code>video-player.js</code> even though the homepage uses
none of that!</p>

<p>This problem gets worse as the number of pages you have goes up, especially if
some of the infrequently visited pages depend on a ton of JavaScript.</p>

<p>The second problem is that your cache hit rate between deploys drops to zero.
Since everything is in one big file now, if you make a 1 line change to some
<code>homepage.js</code> and deploy, everyone has to re-download all of <code>jquery.js</code>,
<code>video-player.js</code> and everything else.</p>

<p>On the upside of cache performance, once you hit one page and download the stuff
you need, as you switch to a different page, you already have all the JS you
need cached in your browser.</p>

<p>Summary of One Big JavaScript File:</p>

<ul>
<li><span>Perfect cache hit rate between page types</span></li>
<li><span>One HTTP round trip</span></li>
<li><span>Excellent compression</span></li>
<li><span>Forces users to download a lot of things they don’t need</span></li>
<li><span>Zero cache hit rate between deploys</span></li>
</ul>


<a name="Solution.3:.One.JS.File.Per.Page"></a>


<p>Since downloading the entire site’s JS in one shot downloads way too much stuff,
why don’t we just download one file that contains all the things we need on a
per-page basis? That would look like this:</p>

<p><img src="http://jamie-wong.com/images/14-11-28/one-file-per-page.png" alt="One File Per Page" /></p>

<p>Then the homepage HTML would have:</p>

<pre><code>    &lt;script src="/build/js/h-package.js"&gt;&lt;/script&gt;
</code></pre>

<p>And the video page would have:</p>

<pre><code>    &lt;script src="/build/js/v-package.js"&gt;&lt;/script&gt;
</code></pre>

<p>This solution fixes the “downloading stuff we don’t need” problem, and also
improves cache performance between deploys. It’s much better than the “one big
file” solution because if you change <code>homepage.js</code> and deploy, your users won’t
need to re-download <code>v-package.js</code> or <code>e-package.js</code> since their contents
haven’t changed. You do still have to redownload all of <code>h-package.js</code> however,
which is sort of a bummer, because it means redownloading the big files like
<code>jquery.js</code> and <code>react.js</code>.</p>

<p>The worse problem is that your cache hit rate betwen pages is zero. Even though
every page uses <code>jquery.js</code>, it’s concatenated into each <code>-package.js</code> file, so
your browser has no idea that it might have it already. This means your browser
will download up to 3 copies of <code>jquery.js</code>: one in each of <code>h-package.js</code>,
<code>v-package.js</code>, and <code>e-package.js</code>.</p>

<p>Summary of One JavaScript File Per Page:</p>

<ul>
<li><span>Downloads only what is needed</span></li>
<li><span>One HTTP round trip per page</span></li>
<li><span>Good compression</span></li>
<li><span>Coarse caching between deploys</span></li>
<li><span>Zero cache hit rate between page types</span></li>
</ul>


<a name="Solution.4:.Many.Concatenated.JS.Files.Per.Page"></a>


<p>As with many things in life, the solution is a compromise. We can’t get all of
the benefits of all of the above solutions with none of the problems, but we can
get rid of the worst problems to get something pretty good.</p>

<p>To provide finer-grained caching and improve cache hit rate between page types
without massively inflating the number of HTTP connections, we go for something
between “one script tag per file” and “one file per page”, and end up with this:</p>

<p><img src="http://jamie-wong.com/images/14-11-28/custom-package-1.png" alt="Custom Packaging 1" /></p>

<p>Once you have a system like this, you can try to balance all of the pros and
cons discussed in previous solutions. The above diagram shows a solution where
each page downloads only exactly what it needs, which is good, but you’ll notice
that <code>react.js</code> and <code>sidebar.js</code> are packaged together. <code>react.js</code> is pretty
big, so ideally I’d like to be able to change <code>sidebar.js</code> without forcing my
users to redownload <code>react.js</code>. I also might want to further minimize the number
of requests on the video and exercises page, and arrive at this:</p>

<p><img src="http://jamie-wong.com/images/14-11-28/custom-package-2.png" alt="Custom Packaging 2" /></p>

<p>So now we have fewer requests, and we won’t break the cache on <code>react.js</code> by
changing something in <code>sidebar.js</code>, but we’re now downloading <code>react.js</code> on the
homepage, and downloading exercise-specific things that we don’t need on the
video page and vice versa.</p>

<p>So of these two packaging policies is better? The answer is (unsurprisingly)
that it depends. How likely is sidebar.js to change? How much compression
benefit do we get from putting <code>jquery.js</code> and <code>react.js</code> in the same
concatenated file?</p>

<p>Khan Academy has been using a variant of Solution 4 since before my first
internship there in 2012, so my job is now mostly concerned with how to optimize
our packages<sup id="fnref:3"><a href="http://jamie-wong.com/2014/11/29/the-js-packaging-problem/#fn:3" rel="footnote">3</a></sup>.</p>

<a name="Optimal.Packaging."></a>


<p>The problem now comes down to two things: which <code>.js</code> files do I concatenate
together into each <code>-package.js</code>, and which <code>-package.js</code> files do I load from
each HTML page<sup id="fnref:4"><a href="http://jamie-wong.com/2014/11/29/the-js-packaging-problem/#fn:4" rel="footnote">4</a></sup>?</p>

<p>Ultimately the goal is to minimize the average time the user spends between
receiving the HTML response from the server and when enough JS runs so that they
can do the thing they want to do on the page.</p>

<p>Even if you had those timings, turning that into actionable modifications to
your file concatenation/package loading policy would be pretty difficult. A more
pragmatic approach is to just have hitcounts for each different HTML page.</p>

<p>Once you have hitcounts for each HTML page, and you know the set of source JS
files (“source” as in “before concatenation”), you can try to figure out how to
move source files between packages in order to reduce the total aggregate number
of bytes users are downloading in a given day<sup id="fnref:5"><a href="http://jamie-wong.com/2014/11/29/the-js-packaging-problem/#fn:5" rel="footnote">5</a></sup>.</p>

<p>At Khan Academy, we’re just now delving into how to do automatic optimization of
our packages, so we don’t have production-proven results to justify which
metrics and algorithms to use to perform these optimizations, but I’ll be sure
to report back when we do.</p>

<a name="Existing.Tools"></a>


<p>For reasons I won’t go into in this post, Khan Academy uses our own in-house
system for both packaging and specifying inter-file dependencies, but plenty of
good open source tools exist that allow you to control how your files get
concatenated together.</p>

<p>The three most battle tested I’m aware of:</p>

<ul>
<li>
<a href="http://webpack.github.io/">webpack</a> with <a href="https://github.com/webpack/docs/wiki/list-of-plugins#commonschunkplugin">CommonsChunkPlugin</a> would be my personal choice for a
new project. webpack tries to be unopinionated and pragmatic, supporting both
synchronous node style <code>require()</code> and AMD style. It’s being used in
production at Instragram. Pete Hunt has a guide up on how it’s used in
production at Instagram: <a href="https://github.com/petehunt/webpack-howto">webpack-howto</a>
</li>
<li>
<a href="http://browserify.org/">Browserify</a> with <a href="https://github.com/substack/factor-bundle">factor-bundle</a>. Browserify uses node style
<code>require()</code>, and factor-bundle is the bit that lets you pull out common
portions to be loaded separately.</li>
<li>
<a href="http://requirejs.org/">RequireJS</a> with the <a href="http://requirejs.org/docs/optimization.html">RequireJS Optimizer</a>. There’s a specific example
for optimizing for multi-page apps: <a href="https://github.com/requirejs/example-multipage">example-multipage</a>.</li>
</ul>



</body></html><span>

</span></div><span>

</span><span>

</span><span>


</span><span>

        </span></div><span>
      </span></div><span>
    </span></div>

    
    <!-- google analytics async -->
    
    
  </div></div>
<script>var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-34802167-1']); _gaq.push(['_setDomainName', 'liuzhe.co']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })();</script></body>
</html>